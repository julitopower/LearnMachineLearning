{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook provides a very simple introduction to [OpenAI Gym](https://gym.openai.com/), a toolkit for developing and comparing reinforcement learning algorithms. For instance, you can use OpenAI Gym to train an agent to play [Atari games!\\(https://gym.openai.com/envs/#atari)\n",
    "\n",
    "![](http://gym.openai.com/videos/2019-04-06--My9IiAbqha/SpaceInvaders-v0/poster.jpg)\n",
    "\n",
    "This notebook **is not** an introcution to Reinforcement Learning, and does not explain concepts like Markov Decision Processes, states, rewards, value functions, policies and so on. For a hands on introduction to reinforcement learning I recommend [Packt: Deep Reinforcement Learning Hands-On](https://www.amazon.com/Deep-Reinforcement-Learning-Hands-Q-networks-ebook/dp/B076H9VQH6/ref=sr_1_1_sspa?keywords=pocket+reinforcement+learning&qid=1555782065&s=gateway&sr=8-1-spons&psc=1). For a solid theoretical treatment of the subject there is nothing better than [Sutton & Barto: Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book-2nd.html), which is available for free online, and can also be [purchased online](https://www.amazon.com/Reinforcement-Learning-Introduction-Adaptive-Computation/dp/0262193981/ref=sr_1_4?crid=17M2H3J2R3L7Z&keywords=sutton+reinforcement+learning&qid=1555782219&s=gateway&sprefix=sutton+re%2Caps%2C200&sr=8-4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before we can get our hands dirty there are a few things we need to install. The following cell takes care of all that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install gym > /dev/null\n",
    "\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all the setup we need. In the following section we will introduce the foundational Gym concepts, and will execute an actual simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Gym\n",
    "\n",
    "OpenAI Gym is very flexible and abstracts many details to make experimentation really fast. The key to this are its foundational concepts: environment, observations, actions and spaces.\n",
    "\n",
    "**Environment**: An environment is a test problem. It models the \"world\" in which the agent exists, generates observations, defines possible actions and determines the reward the agent gets at different points in time. OpenAI Gym is packed with envirnoments. Environments are instanciated by name:\n",
    "\n",
    "```python\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "```\n",
    "\n",
    "**Observations**\n",
    "\n",
    "**Actions**\n",
    "\n",
    "**Spaces**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
